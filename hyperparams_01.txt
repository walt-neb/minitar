num_iterations=20000
initial_collect_steps=5000
collect_steps_per_iteration=10
replay_buffer_capacity=50000
batch_size=128
critic_learning_rate=1e-4
actor_learning_rate=1e-4
alpha_learning_rate=1e-4
target_update_tau=0.01
target_update_period=1
gamma=0.99
reward_scale_factor=1
actor_fc_layer_params=(256, 256)
critic_joint_fc_layer_params=(256, 256)
log_interval=5000
num_eval_episodes=10
eval_interval=500
policy_save_interval=19000

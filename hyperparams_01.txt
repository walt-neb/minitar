num_iterations=30000
initial_collect_steps=10000
collect_steps_per_iteration=5
replay_buffer_capacity=100000
batch_size=128
critic_learning_rate=1e-4
actor_learning_rate=1e-4
alpha_learning_rate=1e-4
target_update_tau=0.01
target_update_period=2
gamma=0.98
reward_scale_factor=2.0
actor_fc_layer_params=(256, 256)
critic_joint_fc_layer_params=(256, 256)
log_interval=1000
num_eval_episodes=10
eval_interval=5000
policy_save_interval=1000

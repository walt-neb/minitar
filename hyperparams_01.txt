num_iterations=2000
initial_collect_steps=5000
collect_steps_per_iteration=1
replay_buffer_capacity=50000
batch_size=64
critic_learning_rate=1e-4
actor_learning_rate=1e-4
alpha_learning_rate=1e-4
target_update_tau=0.005
target_update_period=1
gamma=0.99
reward_scale_factor=1
actor_fc_layer_params=(256, 256)
critic_joint_fc_layer_params=(256, 256)
log_interval=5000
num_eval_episodes=20
eval_interval=500
policy_save_interval=1000
